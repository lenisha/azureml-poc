{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy multiple machine learning models from registry to online endpoint  \n",
    "\n",
    "Learn how to use an online endpoint to deploy your model, so you don't have to create and manage the underlying infrastructure. You'll begin by deploying a model on your local machine to debug any errors, and then you'll deploy and test it in Azure.\n",
    "\n",
    "Managed online endpoints help to deploy your ML models in a turnkey manner. Managed online endpoints work with powerful CPU and GPU machines in Azure in a scalable, fully managed way. Managed online endpoints take care of serving, scaling, securing, and monitoring your models, freeing you from the overhead of setting up and managing the underlying infrastructure. \n",
    "\n",
    "For more information, see [What are Azure Machine Learning endpoints?](https://docs.microsoft.com/azure/machine-learning/concept-endpoints)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* To use Azure Machine Learning, you must have an Azure subscription. If you don't have an Azure subscription, create a free account before you begin. Try the [free or paid version of Azure Machine Learning](https://azure.microsoft.com/free/).\n",
    "\n",
    "* Install and configure the [Python SDK v2](sdk/setup.sh).\n",
    "\n",
    "* You must have an Azure resource group, and you (or the service principal you use) must have Contributor access to it.\n",
    "\n",
    "* You must have an Azure Machine Learning workspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ai.ml` to get a handle to the required Azure Machine Learning workspace. We use the default [default azure authentication](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for this tutorial. Check the [configuration notebook](../../jobs/configuration.ipynb) for more details on how to configure credentials and connect to a workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter details of your AML workspace\n",
    "subscription_id = \"<SUBSCIPTION ID>\"\n",
    "resource_group = \"<RESOURCE_GROUP>\"\n",
    "workspace_name = \"<WORKSPACE>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Deploy your online endpoint to Azure\n",
    "Next, deploy your online endpoint to Azure.\n",
    "\n",
    "## 4.1 Configure online endpoint\n",
    "`endpoint_name`: The name of the endpoint. It must be unique in the Azure region. Naming rules are defined under [managed online endpoint limits](https://docs.microsoft.com/azure/machine-learning/how-to-manage-quotas#azure-machine-learning-managed-online-endpoints-preview).\n",
    "\n",
    "`auth_mode` : Use `key` for key-based authentication. Use `aml_token` for Azure Machine Learning token-based authentication. A `key` does not expire, but `aml_token` does expire. \n",
    "\n",
    "Optionally, you can add description, tags to your endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a unique endpoint name with current datetime to avoid conflicts\n",
    "import datetime\n",
    "\n",
    "online_endpoint_name = \"multimodel-\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is a multimodel online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\"foo\": \"bar\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Create the endpoint\n",
    "\n",
    "Using the `MLClient` created earlier, we will now create the Endpoint in the workspace. This command will start the endpoint creation and return a confirmation response while the endpoint creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://multimodel-03070249904013.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://multimodel-03070249904013.eastus2.inference.ml.azure.com/swagger.json', 'name': 'multimodel-03070249904013', 'description': 'this is a multimodel online endpoint', 'tags': {'foo': 'bar'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourcegroups/openaml/providers/microsoft.machinelearningservices/workspaces/nlp-workspace/onlineendpoints/multimodel-03070249904013', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oe:baa4dabf-18ba-45e2-8649-6d72d7082169:2c243899-2e06-42a5-8e8a-cb5da916e705?api-version=2022-02-01-preview'}, 'id': '/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourceGroups/openaml/providers/Microsoft.MachineLearningServices/workspaces/nlp-workspace/onlineEndpoints/multimodel-03070249904013', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eneros3/code/Users/eneros/azureml-poc/multimodel-registry', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f912ebbba30>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f912ebbb970>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Identity <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f913a0bc490> \n"
     ]
    }
   ],
   "source": [
    "endpoint = ml_client.online_endpoints.get(online_endpoint_name)\n",
    "print(\"Endpoint Identity {0} \".format(endpoint.identity))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.1 Add Role assignment to Managed Endpoint Identity\n",
    "To access ML Models from Registry in workspace MOE System Identity needs to be granted access\n",
    "Assign `AzureML Data Scientist` role to MOE Identity on Workspace scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role {'additional_properties': {}, 'id': '/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/providers/Microsoft.Authorization/roleDefinitions/f6c7c914-8db3-469d-8ca1-694a8f32e121', 'name': 'f6c7c914-8db3-469d-8ca1-694a8f32e121', 'type': 'Microsoft.Authorization/roleDefinitions', 'role_name': 'AzureML Data Scientist', 'description': 'Can perform all actions within an Azure Machine Learning workspace, except for creating or deleting compute resources and modifying the workspace itself.', 'role_type': 'BuiltInRole', 'permissions': [<azure.mgmt.authorization.v2022_04_01.models._models_py3.Permission object at 0x7f912e010c70>], 'assignable_scopes': ['/']}  Found\n",
      "RoleAssignment {'additional_properties': {}, 'id': '/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourceGroups/openaml/providers/Microsoft.MachineLearningServices/workspaces/nlp-workspace/providers/Microsoft.Authorization/roleAssignments/434ca4bf-5e06-4227-9e73-a18bfc6431fd', 'name': '434ca4bf-5e06-4227-9e73-a18bfc6431fd', 'type': 'Microsoft.Authorization/roleAssignments', 'scope': '/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourceGroups/openaml/providers/Microsoft.MachineLearningServices/workspaces/nlp-workspace', 'role_definition_id': '/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/providers/Microsoft.Authorization/roleDefinitions/f6c7c914-8db3-469d-8ca1-694a8f32e121', 'principal_id': 'd630e1e8-ecab-4306-969e-258cedf53860', 'principal_type': 'ServicePrincipal', 'description': None, 'condition': None, 'condition_version': None, 'created_on': datetime.datetime(2023, 3, 7, 3, 0, 11, 927948, tzinfo=<isodate.tzinfo.Utc object at 0x7f915b0ca590>), 'updated_on': datetime.datetime(2023, 3, 7, 3, 0, 12, 175953, tzinfo=<isodate.tzinfo.Utc object at 0x7f915b0ca590>), 'created_by': None, 'updated_by': '633f2146-f81a-4c97-930a-942008ed4871', 'delegated_managed_identity_resource_id': None}  Found\n"
     ]
    }
   ],
   "source": [
    "# add permissions for Workspace\n",
    "import uuid\n",
    "from azure.mgmt.resource.resources import ResourceManagementClient\n",
    "from azure.mgmt.authorization import AuthorizationManagementClient\n",
    "\n",
    "authorization_client = AuthorizationManagementClient(\n",
    "    credential=ml_client._credential,\n",
    "    subscription_id=subscription_id\n",
    ")\n",
    "workspace = ml_client.workspaces.get(name=workspace_name)\n",
    "\n",
    "# Get \"AzureML Data Scientist\" built-in role as a RoleDefinition object\n",
    "role_name = 'AzureML Data Scientist'\n",
    "roles = list(authorization_client.role_definitions.list(\n",
    "    workspace.id,\n",
    "    filter=\"roleName eq '{}'\".format(role_name)\n",
    "))\n",
    "assert len(roles) == 1\n",
    "ml_role = roles[0]\n",
    "\n",
    "print(\"Role {0}  Found\".format(ml_role))\n",
    "\n",
    "\n",
    "# Add WS scope to the Managed Identity token\n",
    "role_assignment = authorization_client.role_assignments.create(\n",
    "        workspace.id,\n",
    "        uuid.uuid4(), # Role assignment random name\n",
    "        {\n",
    "            'role_definition_id': ml_role.id,\n",
    "            'principal_id': endpoint.identity.principal_id\n",
    "        }\n",
    ")\n",
    "print(\"RoleAssignment {0}  Found\".format(role_assignment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Configure online deployment\n",
    "\n",
    "A deployment is a set of resources required for hosting the model that does the actual inferencing. We will create a deployment for our endpoint using the `ManagedOnlineDeployment` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment blue03070412735571  defined\n"
     ]
    }
   ],
   "source": [
    "env = Environment(\n",
    "    conda_file=\"./environment/conda.yml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    ")\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\" + datetime.datetime.now().strftime(\"%m%d%H%M%f\"),\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    #model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"./onlinescoring\", scoring_script=\"score_registry.py\"\n",
    "    ),\n",
    "    environment_variables={\n",
    "        \"TRACKING_URI\": workspace.mlflow_tracking_uri\n",
    "    },\n",
    "    instance_type=\"Standard_F4s_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "print(\"Deployment {0}  defined\".format(blue_deployment.name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Create the deployment\n",
    "\n",
    "Using the `MLClient` created earlier, we will now create the deployment in the workspace. This command will start the deployment creation and return a confirmation response while the deployment creation continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint multimodel-03070249904013 exists\n",
      "Uploading onlinescoring (0.0 MBs): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1956/1956 [00:00<00:00, 60796.92it/s]\n",
      "\n",
      "\n",
      "data_collector is not a known attribute of class <class 'azure.ai.ml._restclient.v2022_02_01_preview.models._models_py3.ManagedOnlineDeployment'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManagedOnlineDeployment({'private_network_connection': False, 'data_collector': None, 'provisioning_state': 'Succeeded', 'endpoint_name': 'multimodel-03070249904013', 'type': 'Managed', 'name': 'blue03070412735571', 'description': None, 'tags': {}, 'properties': {'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/od:baa4dabf-18ba-45e2-8649-6d72d7082169:25b0ee19-0268-4952-8f69-4c04b2e9866a?api-version=2022-02-01-preview'}, 'id': '/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourceGroups/openaml/providers/Microsoft.MachineLearningServices/workspaces/nlp-workspace/onlineEndpoints/multimodel-03070249904013/deployments/blue03070412735571', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eneros3/code/Users/eneros/azureml-poc/multimodel-registry', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f912e0122f0>, 'model': None, 'code_configuration': {'code': '/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourceGroups/openaml/providers/Microsoft.MachineLearningServices/workspaces/nlp-workspace/codes/7cd268e2-39f7-4d3c-8451-2d70761a52e1/versions/1'}, 'environment': '/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourceGroups/openaml/providers/Microsoft.MachineLearningServices/workspaces/nlp-workspace/environments/CliV2AnonymousEnvironment/versions/7145bae4fc75db54dbd9bf27bb29afc7', 'environment_variables': {'TRACKING_URI': 'azureml://eastus2.api.azureml.ms/mlflow/v1.0/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourceGroups/openaml/providers/Microsoft.MachineLearningServices/workspaces/nlp-workspace'}, 'app_insights_enabled': False, 'scale_settings': <azure.ai.ml.entities._deployment.scale_settings.DefaultScaleSettings object at 0x7f912c861120>, 'request_settings': <azure.ai.ml.entities._deployment.deployment_settings.OnlineRequestSettings object at 0x7f912c860d60>, 'liveness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7f912c860970>, 'readiness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7f912c8611b0>, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'Standard_F4s_v2', 'egress_public_network_access': 'Enabled'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Readonly attribute principal_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n",
      "Readonly attribute tenant_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://multimodel-03070249904013.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://multimodel-03070249904013.eastus2.inference.ml.azure.com/swagger.json', 'name': 'multimodel-03070249904013', 'description': 'this is a multimodel online endpoint', 'tags': {'foo': 'bar'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourcegroups/openaml/providers/microsoft.machinelearningservices/workspaces/nlp-workspace/onlineendpoints/multimodel-03070249904013', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oe:baa4dabf-18ba-45e2-8649-6d72d7082169:975c6951-5a3c-41ea-b4e5-b2ac288e3944?api-version=2022-02-01-preview'}, 'id': '/subscriptions/f9b97038-ed78-4a26-a1a7-51e81e75d867/resourceGroups/openaml/providers/Microsoft.MachineLearningServices/workspaces/nlp-workspace/onlineEndpoints/multimodel-03070249904013', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eneros3/code/Users/eneros/azureml-poc/multimodel-registry', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7f912c86f4f0>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7f912e0dd3c0>, 'traffic': {'blue03070412735571': 100}, 'mirror_traffic': {}, 'kind': 'Managed'})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# blue deployment takes 100 traffic\n",
    "endpoint.traffic = {f\"{blue_deployment.name}\": 100}\n",
    "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test the endpoint with sample data\n",
    "Using the `MLClient` created earlier, we will get a handle to the endpoint. The endpoint can be invoked using the `invoke` command with the following parameters:\n",
    "- `endpoint_name` - Name of the endpoint\n",
    "- `request_file` - File with request data\n",
    "- `deployment_name` - Name of the specific deployment to test in an endpoint\n",
    "\n",
    "We will send a sample request using a [json](./model-1/sample-request.json) file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\"]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the blue deployment with some sample data\n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=blue_deployment.name,\n",
    "    request_file=\"./onlinescoring/sample-request.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Managing endpoints and deployments\n",
    "\n",
    "## 6.1 Get details of the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blue03070412735571': 100, 'blue03070404167155': 0, 'blue03070330299288': 0}\n",
      "https://multimodel-03070249904013.eastus2.inference.ml.azure.com/score\n"
     ]
    }
   ],
   "source": [
    "# Get the details for online endpoint\n",
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "# existing traffic details\n",
    "print(endpoint.traffic)\n",
    "\n",
    "# Get the scoring URI\n",
    "print(endpoint.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Get the logs for the new deployment\n",
    "Get the logs for the green deployment and verify as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Instance status:\\nSystemSetup: Succeeded\\nUserContainerImagePull: Succeeded\\nModelDownload: Succeeded\\nUserContainerStart: Succeeded\\n\\nContainer events:\\nKind: Pod, Name: Downloading, Type: Normal, Time: 2023-03-07T04:17:09.637642Z, Message: Start downloading models\\nKind: Pod, Name: Pulling, Type: Normal, Time: 2023-03-07T04:17:09.817112Z, Message: Start pulling container image\\nKind: Pod, Name: Pulled, Type: Normal, Time: 2023-03-07T04:17:53.479987Z, Message: Container image is pulled successfully\\nKind: Pod, Name: Downloaded, Type: Normal, Time: 2023-03-07T04:17:53.479987Z, Message: Models are downloaded successfully\\nKind: Pod, Name: Created, Type: Normal, Time: 2023-03-07T04:17:53.661293Z, Message: Created container inference-server\\nKind: Pod, Name: Started, Type: Normal, Time: 2023-03-07T04:17:53.741896Z, Message: Started container inference-server\\nKind: Pod, Name: ContainerReady, Type: Normal, Time: 2023-03-07T04:18:07.588068045Z, Message: Container is ready\\n\\nContainer logs:\\n    \\'Last-Modified\\': \\'Tue, 07 Mar 2023 02:26:07 GMT\\'\\n    \\'Accept-Ranges\\': \\'REDACTED\\'\\n    \\'ETag\\': \\'\"0x8DB1EB34EA36CB8\"\\'\\n    \\'Vary\\': \\'REDACTED\\'\\n    \\'Server\\': \\'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0\\'\\n    \\'x-ms-request-id\\': \\'a94b449b-a01e-0059-73ab-5047b7000000\\'\\n    \\'x-ms-client-request-id\\': \\'0c2ad6b6-bc9f-11ed-89b7-ae7e23771fd2\\'\\n    \\'x-ms-version\\': \\'REDACTED\\'\\n    \\'x-ms-creation-time\\': \\'REDACTED\\'\\n    \\'x-ms-blob-content-md5\\': \\'REDACTED\\'\\n    \\'x-ms-lease-status\\': \\'REDACTED\\'\\n    \\'x-ms-lease-state\\': \\'REDACTED\\'\\n    \\'x-ms-blob-type\\': \\'REDACTED\\'\\n    \\'x-ms-server-encrypted\\': \\'REDACTED\\'\\n    \\'Date\\': \\'Tue, 07 Mar 2023 04:18:00 GMT\\'\\nInit complete\\n2023-03-07 04:18:00,964 | root | INFO | Users\\'s init has completed successfully\\n00000000-0000-0000-0000-000000000000,/azureml-envs/azureml_eff148b6633c690a0f9f96b56b6cc759/lib/python3.7/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator SVC from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\\n  UserWarning)\\n2023-03-07 04:18:00,965 | root | INFO | Swaggers are prepared for the following versions: [2, 3].\\n2023-03-07 04:18:00,965 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\\n2023-03-07 04:18:00,965 | root | INFO | AML_FLASK_ONE_COMPATIBILITY is set. Patched Flask to ensure compatibility with Flask 1.\\n2023-03-07 04:20:25,199 | root | INFO | 200\\n127.0.0.1 - - [07/Mar/2023:04:20:25 +0000] \"GET /swagger.json HTTP/1.0\" 200 2253 \"-\" \"-\"\\nRequest received\\ndfe85beb-522d-4301-aaf8-57cc3839b750,{\"columns\": [0, 1, 2, 3], \"index\": [0, 1, 2], \"data\": [[5, 3.3, 1.4, 0.2], [6.1, 2.9, 4.7, 1.4], [6, 3, 4.8, 1.8]]}\\n Model 2 is predicting\\nRequest processed\\n2023-03-07 04:20:46,977 | root | INFO | 200\\n127.0.0.1 - - [07/Mar/2023:04:20:46 +0000] \"POST /score?verbose=true HTTP/1.0\" 200 52 \"-\" \"-\"\\nRequest received\\nb188ac42-a6ba-4302-8c9b-619c0fbede34,{\"columns\": [0, 1, 2, 3], \"index\": [0, 1, 2], \"data\": [[5, 3.3, 1.4, 0.2], [6.1, 2.9, 4.7, 1.4], [6, 3, 4.8, 1.8]]}\\n Model 2 is predicting\\nRequest processed\\n2023-03-07 04:20:52,500 | root | INFO | 200\\n127.0.0.1 - - [07/Mar/2023:04:20:52 +0000] \"POST /score?verbose=true HTTP/1.0\" 200 52 \"-\" \"-\"\\n2023-03-07 04:21:13,840 | root | INFO | 200\\n127.0.0.1 - - [07/Mar/2023:04:21:13 +0000] \"GET /swagger.json HTTP/1.0\" 200 2253 \"-\" \"-\"\\nRequest received\\n2aa7f80a-fedc-4a0d-bc4f-d90f97d1970d,{\"columns\": [0, 1, 2, 3], \"index\": [0, 1, 2], \"data\": [[5, 3.3, 1.4, 0.2], [6.1, 2.9, 4.7, 1.4]]}\\n Model 1 is predicting\\nRequest processed\\n2023-03-07 04:21:25,278 | root | INFO | 200\\n127.0.0.1 - - [07/Mar/2023:04:21:25 +0000] \"POST /score?verbose=true HTTP/1.0\" 200 34 \"-\" \"-\"\\nRequest received\\n45633680-2fb6-46d8-80f6-dc99c21bc893,{\"columns\": [0, 1, 2, 3], \"index\": [0, 1, 2], \"data\": [[5, 3.3, 1.4, 0.2], [6.1, 2.9, 4.7, 1.4], [6, 3, 4.8, 1.8]]}\\n Model 2 is predicting\\nRequest processed\\n2023-03-07 04:22:30,550 | root | INFO | 200\\n127.0.0.1 - - [07/Mar/2023:04:22:30 +0000] \"POST /score HTTP/1.0\" 200 52 \"-\" \"azure-ai-ml/1.2.0 azsdk-python-core/1.26.2 Python/3.10.9 (Linux-5.15.0-1031-azure-x86_64-with-glibc2.31)\"\\n\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_client.online_deployments.get_logs(\n",
    "    name=blue_deployment.name, endpoint_name=online_endpoint_name, lines=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Delete the endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Use an online endpoint to deploy your model, so you don't have to create and manage the underlying infrastructure"
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78f9db5fbd37e8889e0f83cef79d3f22c09395ee4e0648cc45e2c02045ffa952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
